{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import megengine.functional as F\n",
    "import megengine.module as M\n",
    "import megengine as mge\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "class Upsample(M.Module):\n",
    "\n",
    "    def __init__(self, scale_factor=2, mode=\"bilinear\"):\n",
    "        super().__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.vision.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n",
    "\n",
    "\n",
    "class SiLU(M.Module):\n",
    "    \"\"\"export-friendly version of M.SiLU()\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(x):\n",
    "        return x * F.sigmoid(x)\n",
    "\n",
    "\n",
    "def get_activation(name=\"silu\"):\n",
    "    if name == \"silu\":\n",
    "        if hasattr(M, \"SiLU\"):\n",
    "            module = M.SiLU()\n",
    "        else:\n",
    "            module = SiLU()\n",
    "    elif name == \"relu\":\n",
    "        module = M.ReLU()\n",
    "    elif name == \"lrelu\":\n",
    "        module = M.LeakyReLU(0.1)\n",
    "    else:\n",
    "        raise AttributeError(\"Unsupported act type: {}\".format(name))\n",
    "    return module\n",
    "\n",
    "\n",
    "class Conv(M.Module):\n",
    "    \"\"\"A Conv2d -> Batchnorm -> silu/leaky relu block\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, ksize, stride, groups=1, bias=False, act=\"silu\"):\n",
    "        super().__init__()\n",
    "        # same padding\n",
    "        pad = (ksize - 1) // 2\n",
    "        self.conv = M.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=ksize,\n",
    "            stride=stride,\n",
    "            padding=pad,\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "        )\n",
    "        self.bn = M.BatchNorm2d(out_channels)\n",
    "        self.act = get_activation(act)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "    def fuseforward(self, x):\n",
    "        return self.act(self.conv(x))\n",
    "\n",
    "\n",
    "class DWConv(M.Module):\n",
    "    \"\"\"Depthwise Conv + Conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, ksize, stride=1, act=\"silu\"):\n",
    "        super().__init__()\n",
    "        self.dconv = Conv(\n",
    "            in_channels, in_channels, ksize=ksize,\n",
    "            stride=stride, groups=in_channels, act=act\n",
    "        )\n",
    "        self.pconv = Conv(\n",
    "            in_channels, out_channels, ksize=1,\n",
    "            stride=1, groups=1, act=act\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dconv(x)\n",
    "        return self.pconv(x)\n",
    "\n",
    "\n",
    "class Bottleneck(M.Module):\n",
    "    # Standard bottleneck\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, shortcut=True,\n",
    "        expansion=0.5, depthwise=False, act=\"silu\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_channels = int(out_channels * expansion)\n",
    "        # Conv = DWConv if depthwise else Conv\n",
    "        self.conv1 = Conv(in_channels, hidden_channels, 1, stride=1, act=act)\n",
    "        self.conv2 = Conv(hidden_channels, out_channels, 3, stride=1, act=act)\n",
    "        self.use_add = shortcut and in_channels == out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv2(self.conv1(x))\n",
    "        if self.use_add:\n",
    "            y = y + x\n",
    "        return y\n",
    "\n",
    "\n",
    "class C3(M.Module):\n",
    "    \"\"\"C3 in yolov5, CSP Bottleneck with 3 convolutions\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, n=1,\n",
    "        shortcut=True, expansion=0.5, depthwise=False, act=\"silu\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): input channels.\n",
    "            out_channels (int): output channels.\n",
    "            n (int): number of Bottlenecks. Default value: 1.\n",
    "        \"\"\"\n",
    "        # ch_in, ch_out, number, shortcut, groups, expansion\n",
    "        super().__init__()\n",
    "        hidden_channels = int(out_channels * expansion)  # hidden channels\n",
    "        self.conv1 = Conv(in_channels, hidden_channels, 1, stride=1, act=act)\n",
    "        self.conv2 = Conv(in_channels, hidden_channels, 1, stride=1, act=act)\n",
    "        self.conv3 = Conv(2 * hidden_channels, out_channels, 1, stride=1, act=act)\n",
    "        module_list = [\n",
    "            Bottleneck(hidden_channels, hidden_channels, shortcut, 1.0, depthwise, act=act)\n",
    "            for _ in range(n)\n",
    "        ]\n",
    "        self.m = M.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.conv1(x)\n",
    "        x_2 = self.conv2(x)\n",
    "        x_1 = self.m(x_1)\n",
    "        x = F.concat((x_1, x_2), axis=1)\n",
    "        return self.conv3(x)\n",
    "\n",
    "\n",
    "class SPPF(M.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5):\n",
    "        super().__init__()\n",
    "        in_half_channels = in_channels // 2\n",
    "        self.conv1 = Conv(in_channels, in_half_channels, 1, 1)\n",
    "        self.conv2 = Conv(in_half_channels*4, out_channels, 1, 1)\n",
    "        self.maxpool = M.MaxPool2d(kernel_size=kernel_size, stride=1, padding=kernel_size//2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        y1 = self.maxpool(x)\n",
    "        y2 = self.maxpool(y1)\n",
    "        y3 = self.maxpool(y2)\n",
    "        concat_all = F.concat([x, y1, y2, y3],axis=1)\n",
    "        output = self.conv2(concat_all)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Concat(M.Module):\n",
    "    def __init__(self, dimension=1):\n",
    "        super().__init__()\n",
    "        self.d = dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.concat(x,self.d)\n",
    "\n",
    "class Reshape(M.Module):\n",
    "    def __init__(self, target_shape):\n",
    "        super.__init__()\n",
    "        self.t_shape = target_shape\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.reshape(x, self.t_shape)\n",
    "\n",
    "\n",
    "def meshgrid(x, y):\n",
    "    # meshgrid wrapper for megengine\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    mesh_shape = (y.shape[0], x.shape[0])\n",
    "    mesh_x = F.broadcast_to(x, mesh_shape)\n",
    "    mesh_y = F.broadcast_to(y.reshape(-1, 1), mesh_shape)\n",
    "    return mesh_x, mesh_y \n",
    " \n",
    " \n",
    "class YoloHead(M.Module):\n",
    "    def __init__(self, image_shape, num_class, is_training, strides, anchors, anchors_masks):\n",
    "        super().__init__()\n",
    "        self.image_shape = image_shape\n",
    "        self.num_class = num_class\n",
    "        self.is_training = is_training\n",
    "        self.strides = strides\n",
    "        self.anchors = anchors\n",
    "        self.anchors_masks = anchors_masks\n",
    "        self.grid = []\n",
    "        self.anchor_grid = []\n",
    "        for i, stride in enumerate(strides):\n",
    "            grid, anchor_grid = self._make_grid(self.image_shape[0] // stride, self.image_shape[1] // stride, i)\n",
    "            self.grid.append(grid)\n",
    "            self.anchor_grid.append(anchor_grid)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        detect_res = []\n",
    "        for i, pred in enumerate(inputs):\n",
    "            if not self.is_training:\n",
    "                pred = F.sigmoid(pred)\n",
    "                f_shape = pred.shape\n",
    "                # if len(self.grid) < self.anchor_masks.shape[0]:\n",
    "                #     grid, anchor_grid = self._make_grid(f_shape[1], f_shape[2], i)\n",
    "                #     self.grid.append(grid)\n",
    "                #     self.anchor_grid.append(anchor_grid)\n",
    "                # 这里把输出的值域从[0,1]调整到[0, image_shape]\n",
    "                # pred_xy = (tf.sigmoid(pred[..., 0:2]) * 2. - 0.5 + self.grid[i]) * self.strides[i]\n",
    "                pred_xy = (pred[..., 0:2] * 2. - 0.5 + self.grid[i]) * self.strides[i]\n",
    "                # pred_wh = (tf.sigmoid(pred[..., 2:4]) * 2) ** 2 * self.anchor_grid[i]\n",
    "                pred_wh = (pred[..., 2:4] * 2) * (pred[..., 2:4] * 2) * self.anchor_grid[i]\n",
    "                # print(self.grid)\n",
    "                pred_obj = pred[..., 4:5]\n",
    "                # pred_cls = tf.keras.layers.Softmax()(pred[..., 5:])\n",
    "                pred_cls = pred[..., 5:]\n",
    "                cur_layer_pred_res = M.Concat([pred_xy, pred_wh, pred_obj, pred_cls], axis=-1)\n",
    "\n",
    "                # cur_layer_pred_res = tf.reshape(cur_layer_pred_res, [self.batch_size, -1, self.num_class + 5])\n",
    "                cur_layer_pred_res = Reshape([f_shape[1]*f_shape[2]*f_shape[3], self.num_class + 5])(cur_layer_pred_res)\n",
    "                detect_res.append(cur_layer_pred_res)\n",
    "            else:\n",
    "                detect_res.append(pred)\n",
    "        return detect_res if self.is_training else F.concat(detect_res, axis=1)\n",
    "    \n",
    "    # tested\n",
    "    def _make_grid(self, h, w, i):\n",
    "        cur_layer_anchors = self.anchors[self.anchors_masks[i]] * np.array([[self.image_shape[1], self.image_shape[0]]])\n",
    "        cur_layer_anchors = mge.Tensor(cur_layer_anchors)\n",
    "        num_anchors_per_layer = len(cur_layer_anchors)\n",
    "        yv, xv = meshgrid(F.arange(h), F.arange(w))\n",
    "        grid = F.stack((xv, yv), axis=2)\n",
    "        # 用来计算中心点的grid cell左上角坐标\n",
    "        grid = F.tile(F.reshape(grid, [1, h, w, 1, 2]), [1, 1, 1, num_anchors_per_layer, 1])\n",
    "        grid = mge.Tensor(grid, dtype = \"float32\")\n",
    "        # anchor_grid = tf.reshape(cur_layer_anchors * self.strides[i], [1, 1, 1, num_anchors_per_layer, 2])\n",
    "        anchor_grid = F.reshape(cur_layer_anchors, [1, 1, 1, num_anchors_per_layer, 2])\n",
    "        # 用来计算宽高的anchor w/h\n",
    "        anchor_grid = F.tile(anchor_grid, [1, h, w, 1, 1])\n",
    "        anchor_grid = mge.Tensor(anchor_grid, dtype = \"float32\")\n",
    "\n",
    "        return grid, anchor_grid\n",
    "\n",
    "\n",
    "def nms(image_shape, predicts, conf_thres=0.45, iou_thres=0.2, max_det=300, max_nms=3000):\n",
    "    \n",
    "    output = []\n",
    "\n",
    "    for i, predict in enumerate(predicts):\n",
    "        obj_mask = predict[..., 4] > conf_thres\n",
    "        predict = predict[obj_mask]\n",
    "\n",
    "        if not predict.shape[0]:\n",
    "            continue\n",
    "        predict[:, 5:] *= predict[:, 4:5]\n",
    "\n",
    "        x1 = np.maximum(predict[:, 0] - predict[:, 2] / 2, 0)\n",
    "        y1 = np.maximum(predict[:, 1] - predict[:, 3] / 2, 0)\n",
    "        x2 = np.minimum(predict[:, 0] + predict[:, 2] / 2, image_shape[1])\n",
    "        y2 = np.minimum(predict[:, 1] + predict[:, 3] / 2, image_shape[0])\n",
    "        box = np.concatenate([x1[:, None], y1[:, None], x2[:, None], y2[:, None]], axis=-1)\n",
    "        # Detections matrix [n, (x1, y1, x2, y2, conf, cls)]\n",
    "        max_cls_ids = np.array(predict[:, 5:].argmax(axis=1), dtype=np.float32)\n",
    "        max_cls_score = predict[:, 5:].max(axis=1)\n",
    "        predict = np.concatenate([box, max_cls_score[:, None], max_cls_ids[:, None]], axis=1)[\n",
    "            np.reshape(max_cls_score > 0.1, (-1,))]\n",
    "\n",
    "        n = predict.shape[0]\n",
    "        if not n:\n",
    "            continue\n",
    "        elif n > max_nms:\n",
    "            predict = predict[predict[:, 4].argsort()[::-1][:max_nms]]\n",
    "\n",
    "        # 为每个类别乘上一个大数,box再加上这个偏移, 做nms时就可以在类内做\n",
    "        cls = predict[:, 5:6] * 4096\n",
    "        # 边框加偏移\n",
    "        boxes, scores = predict[:, :4] + cls, predict[:, 4]\n",
    "        nms_ids = F.vision.nms(\n",
    "            boxes, scores, iou_thres, max_det)\n",
    "\n",
    "        output.append(predict[nms_ids.numpy()])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3(\n",
      "  (conv1): Conv(\n",
      "    (conv): Conv2d(64, 32, kernel_size=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (conv2): Conv(\n",
      "    (conv): Conv2d(64, 32, kernel_size=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (conv3): Conv(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "SPPF(\n",
      "  (conv1): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (conv2): Conv(\n",
      "    (conv): Conv2d(1024, 1024, kernel_size=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=5, stride=1, padding=2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "c3 = C3(64,64)\n",
    "print(c3)\n",
    "sppf = SPPF(512,1024)\n",
    "print(sppf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(h, w, i):\n",
    "    image_shape = (640, 640, 3)\n",
    "    anchors = np.array([[10, 13], [16, 30], [33, 23],\n",
    "                        [30, 61], [62, 45], [59, 119],\n",
    "                        [116, 90], [156, 198], [373, 326]]) / image_shape[0]\n",
    "    anchor_masks = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]], dtype=np.int8)\n",
    "    cur_layer_anchors = anchors[anchor_masks[i]] * np.array([[image_shape[1], image_shape[0]]])\n",
    "    cur_layer_anchors = mge.Tensor(cur_layer_anchors)\n",
    "    num_anchors_per_layer = len(cur_layer_anchors)\n",
    "    yv, xv = meshgrid(F.arange(h), F.arange(w))\n",
    "    grid = F.stack((xv, yv), axis=2)\n",
    "    # 用来计算中心点的grid cell左上角坐标\n",
    "    grid = F.tile(F.reshape(grid, [1, h, w, 1, 2]), [1, 1, 1, num_anchors_per_layer, 1])\n",
    "    grid = mge.Tensor(grid, dtype = \"float32\")\n",
    "    # anchor_grid = tf.reshape(cur_layer_anchors * self.strides[i], [1, 1, 1, num_anchors_per_layer, 2])\n",
    "    anchor_grid = F.reshape(cur_layer_anchors, [1, 1, 1, num_anchors_per_layer, 2])\n",
    "    # 用来计算宽高的anchor w/h\n",
    "    anchor_grid = F.tile(anchor_grid, [1, h, w, 1, 1])\n",
    "    anchor_grid = mge.Tensor(anchor_grid, dtype = \"float32\")\n",
    "\n",
    "    return grid, anchor_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20, 20, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "grid, anchor_grid = make_grid(20,20,0)\n",
    "print(anchor_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[[[1. 2.]\n",
      "   [3. 4.]]]], device=xpux:0)\n",
      "[[[[1.   1.25 1.75 2.  ]\n",
      "   [1.5  1.75 2.25 2.5 ]\n",
      "   [2.5  2.75 3.25 3.5 ]\n",
      "   [3.   3.25 3.75 4.  ]]]] [[[[1.   1.25 1.75 2.  ]\n",
      "   [1.5  1.75 2.25 2.5 ]\n",
      "   [2.5  2.75 3.25 3.5 ]\n",
      "   [3.   3.25 3.75 4.  ]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from megengine import Tensor\n",
    "x = Tensor(np.arange(1, 5, dtype=np.float32).reshape(1, 1, 2, 2))\n",
    "print(x)\n",
    "out = F.vision.interpolate(x, [4, 4], align_corners=False)\n",
    "out.numpy()\n",
    "out2 = F.vision.interpolate(x, scale_factor=2.)\n",
    "print(out.numpy(), out2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = mge.tensor(np.random.randn(1, 256, 40, 40).astype(np.float32))\n",
    "y_1 = mge.tensor(np.random.randn(1, 256, 40, 40).astype(np.float32))\n",
    "F.concat(x_1, y_1, axis=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
